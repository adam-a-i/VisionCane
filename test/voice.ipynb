{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:49:15.492404Z",
     "start_time": "2025-02-09T07:49:15.306825Z"
    }
   },
   "source": [
    "import speech_recognition as sr\n",
    "from rapidfuzz import process\n",
    "\n",
    "# List of predefined commands\n",
    "commands = [\n",
    "    \"start navigation\",\n",
    "    \"stop navigation\",\n",
    "    \"zoom in\",\n",
    "    \"zoom out\",\n",
    "    \"find shortest route\",\n",
    "    \"reroute\",\n",
    "    \"exit application\"\n",
    "]\n",
    "\n",
    "\n",
    "def recognize_speech():\n",
    "    \"\"\"Capture speech input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for a command...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Helps with background noise\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5)  # Listen with a timeout\n",
    "            text = recognizer.recognize_google(audio)  # Convert speech to text\n",
    "            return text.lower()\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError:\n",
    "            print(\"Could not request results from speech recognition service.\")\n",
    "            return None\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Listening timed out.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def find_best_match(heard_command):\n",
    "    \"\"\"Find the best matching command from the list.\"\"\"\n",
    "    if not heard_command:\n",
    "        return None, None, 0\n",
    "\n",
    "    best_match, score, _ = process.extractOne(heard_command, commands)\n",
    "    return heard_command, best_match, score\n",
    "\n",
    "\n",
    "# Continuous listening loop\n",
    "print(\"Voice command system activated. Say a command:\")\n",
    "while True:\n",
    "    heard_command = recognize_speech()\n",
    "    if heard_command:\n",
    "        heard, matched, score = find_best_match(heard_command)\n",
    "        print(f\"Heard: {heard}\")\n",
    "        print(f\"Matched Command: {matched}\")\n",
    "        print(f\"Match Score: {score}\")\n",
    "\n",
    "        if matched == \"exit application\":\n",
    "            print(\"Exiting program...\")\n",
    "            break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice command system activated. Say a command:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/speech_recognition/__init__.py:103\u001B[0m, in \u001B[0;36mMicrophone.get_pyaudio\u001B[0;34m()\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpyaudio\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyaudio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVoice command system activated. Say a command:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 46\u001B[0m     heard_command \u001B[38;5;241m=\u001B[39m \u001B[43mrecognize_speech\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m heard_command:\n\u001B[1;32m     48\u001B[0m         heard, matched, score \u001B[38;5;241m=\u001B[39m find_best_match(heard_command)\n",
      "Cell \u001B[0;32mIn[22], line 18\u001B[0m, in \u001B[0;36mrecognize_speech\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Capture speech input and convert it to text.\"\"\"\u001B[39;00m\n\u001B[1;32m     17\u001B[0m recognizer \u001B[38;5;241m=\u001B[39m sr\u001B[38;5;241m.\u001B[39mRecognizer()\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMicrophone\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m source:\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mListening for a command...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     20\u001B[0m     recognizer\u001B[38;5;241m.\u001B[39madjust_for_ambient_noise(source)  \u001B[38;5;66;03m# Helps with background noise\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/speech_recognition/__init__.py:75\u001B[0m, in \u001B[0;36mMicrophone.__init__\u001B[0;34m(self, device_index, sample_rate, chunk_size)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk_size, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m chunk_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChunk size must be a positive integer\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# set up PyAudio\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyaudio_module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_pyaudio\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m audio \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyaudio_module\u001B[38;5;241m.\u001B[39mPyAudio()\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/speech_recognition/__init__.py:105\u001B[0m, in \u001B[0;36mMicrophone.get_pyaudio\u001B[0;34m()\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpyaudio\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m--> 105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find PyAudio; check installation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pyaudio\n",
      "\u001B[0;31mAttributeError\u001B[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T07:49:15.515882237Z",
     "start_time": "2025-02-09T07:29:44.042581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import whisper\n",
    "import queue\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"small\")  # Use \"tiny\", \"base\", \"small\", \"medium\", or \"large\"\n",
    "\n",
    "# Parameters\n",
    "sample_rate = 16000  # Whisper works best with 16kHz sample rate\n",
    "block_size = 1024  # Number of frames per block\n",
    "channels = 1  # Mono audio\n",
    "duration = 5  # Maximum duration of each command in seconds\n",
    "\n",
    "# Queue to hold audio data\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This is called for each audio block from the microphone.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "\n",
    "def play_audio(audio_data):\n",
    "    \"\"\"Play back the recorded audio.\"\"\"\n",
    "    print(\"Playing back audio...\")\n",
    "    sd.play(audio_data, samplerate=sample_rate)\n",
    "    sd.wait()  # Wait until the audio is finished playing\n",
    "    print(\"Playback finished.\")\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_data):\n",
    "    \"\"\"Transcribe audio data using Whisper.\"\"\"\n",
    "    audio_data = audio_data.flatten().astype(np.float32)  # Normalize to [-1, 1]\n",
    "    result = model.transcribe(audio_data, fp16=False, language=\"en\")  # Disable FP16 if not using a GPU\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def record_and_transcribe():\n",
    "    \"\"\"Record audio, play it back, and transcribe it.\"\"\"\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=sample_rate, blocksize=block_size,\n",
    "                            channels=channels, callback=audio_callback):\n",
    "            while True:\n",
    "                # Collect audio data for the specified duration\n",
    "                audio_frames = []\n",
    "                while not audio_queue.empty():\n",
    "                    audio_queue.get()\n",
    "                print(\"Listening... Speak now!\")\n",
    "                for _ in range(int(sample_rate / block_size * duration)):\n",
    "                    audio_frames.append(audio_queue.get())\n",
    "\n",
    "                # Combine audio frames into a single array\n",
    "                audio_data = np.concatenate(audio_frames)\n",
    "\n",
    "                # Play back the recorded audio\n",
    "                # play_audio(audio_data)\n",
    "\n",
    "                # Transcribe the audio\n",
    "                transcription = transcribe_audio(audio_data)\n",
    "                print(f\"Transcription: {transcription}\")\n",
    "\n",
    "                # Exit if the user says \"exit\"\n",
    "                if \"exit\" in transcription.lower():\n",
    "                    print(\"Exiting...\")\n",
    "                    break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nRecording stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    record_and_transcribe()"
   ],
   "id": "480723e515e8b84d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening... Speak now!\n",
      "Transcription:  you\n",
      "Listening... Speak now!\n",
      "Transcription: \n",
      "Listening... Speak now!\n",
      "Transcription: \n",
      "Listening... Speak now!\n",
      "Transcription: \n",
      "Listening... Speak now!\n",
      "Transcription: \n",
      "Listening... Speak now!\n",
      "\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T20:02:29.435513Z",
     "start_time": "2025-02-09T20:01:35.745447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import whisper\n",
    "import queue\n",
    "from collections import deque\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"small\")  # Use \"tiny\", \"base\", \"small\", \"medium\", or \"large\"\n",
    "\n",
    "# Parameters\n",
    "sample_rate = 16000  # Whisper works best with 16kHz sample rate\n",
    "block_size = 1024  # Number of frames per block\n",
    "channels = 1  # Mono audio\n",
    "silence_threshold = 0.2  # Threshold for silence detection\n",
    "min_silence_duration = 1.5  # Minimum silence duration to consider the user has stopped speaking\n",
    "trigger_term = \"hey computer\"  # The trigger term to activate command listening\n",
    "window_duration = 2.0  # Duration of the moving window in seconds\n",
    "check_interval = 0.1  # Check the window every 100ms\n",
    "\n",
    "# Queue to hold audio data\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This is called for each audio block from the microphone.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "\n",
    "def is_silent(audio_data):\n",
    "    \"\"\"Check if the audio data is silent based on energy threshold.\"\"\"\n",
    "    np.abs(audio_data)\n",
    "    return np.sqrt(np.mean(audio_data ** 2)) < silence_threshold\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_data):\n",
    "    \"\"\"Transcribe audio data using Whisper.\"\"\"\n",
    "    audio_data = audio_data.flatten().astype(np.float32)\n",
    "    result = model.transcribe(audio_data, fp16=False, language='en')  # Disable FP16 if not using a GPU\n",
    "    return result[\"text\"].strip().lower()\n",
    "\n",
    "\n",
    "def listen_for_trigger():\n",
    "    \"\"\"Listen for the trigger term using a moving window.\"\"\"\n",
    "    print(\"Listening for trigger term...\")\n",
    "    buffer = deque(maxlen=int(sample_rate * window_duration / block_size))  # Sliding buffer for 2 seconds of audio\n",
    "    last_check_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        # Collect audio data\n",
    "        if not audio_queue.empty():\n",
    "            buffer.append(audio_queue.get())\n",
    "\n",
    "        # Check the window every 100ms\n",
    "        if time.time() - last_check_time >= check_interval:\n",
    "            if len(buffer) > 0:\n",
    "                # Concatenate the audio data in the buffer\n",
    "                audio_data = np.concatenate(buffer)\n",
    "                transcription = transcribe_audio(audio_data)\n",
    "                print(f\"Heard: {transcription}\")\n",
    "\n",
    "                # Check if the trigger term is detected\n",
    "                if trigger_term in transcription:\n",
    "                    print(f\"Trigger term '{trigger_term}' detected!\")\n",
    "                    return True\n",
    "\n",
    "            last_check_time = time.time()\n",
    "\n",
    "\n",
    "def listen_for_command():\n",
    "    \"\"\"Listen for a command after the trigger term is detected.\"\"\"\n",
    "    print(\"Listening for command...\")\n",
    "    audio_frames = []\n",
    "    last_speech_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        # Collect audio data\n",
    "        if not audio_queue.empty():\n",
    "            audio_data = audio_queue.get()\n",
    "            audio_frames.append(audio_data)\n",
    "\n",
    "            # Check if the audio is silent\n",
    "            if is_silent(audio_data):\n",
    "                if time.time() - last_speech_time > min_silence_duration:\n",
    "                    # User has stopped speaking\n",
    "                    break\n",
    "            else:\n",
    "                last_speech_time = time.time()\n",
    "\n",
    "    # Transcribe the command\n",
    "    audio_data = np.concatenate(audio_frames)\n",
    "    command = transcribe_audio(audio_data)\n",
    "    print(f\"Command: {command}\")\n",
    "    return command\n",
    "\n",
    "\n",
    "def process_command(command):\n",
    "    \"\"\"Process the transcribed command.\"\"\"\n",
    "    print(f\"Processing command: {command}\")\n",
    "    # Add your command processing logic here\n",
    "    if \"exit\" in command:\n",
    "        print(\"Exiting...\")\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main loop to listen for trigger terms and commands.\"\"\"\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=sample_rate, blocksize=block_size,\n",
    "                            channels=channels, callback=audio_callback):\n",
    "            while True:\n",
    "                # Listen for the trigger term using a moving window\n",
    "                if listen_for_trigger():\n",
    "                    # Listen for a command\n",
    "                    command = listen_for_command()\n",
    "                    # Process the command\n",
    "                    process_command(command)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExiting...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "5c3e3905e3b38453",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for trigger term...\n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: \n",
      "Heard: \n",
      "Heard: \n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: \n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: jesus, this is terence town.\n",
      "Heard: what are the worlds most renowned men?\n",
      "Heard: \n",
      "Heard: right now is an outcast.\n",
      "Heard: just to show you guys what i mean.\n",
      "Heard: \n",
      "Heard: \n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T14:49:45.478499397Z",
     "start_time": "2025-02-09T14:30:37.489389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.whisper_voice_command import VoiceCommandListener\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    listener = VoiceCommandListener()\n",
    "\n",
    "    # Set up triggers (terms to be detected, and whether they should be included or not)\n",
    "    listener.set_triggers([(\"hey computer\", True)])\n",
    "\n",
    "\n",
    "    # Set a custom command listener\n",
    "    def custom_command_listener(command):\n",
    "        print(f\"Custom command listener received command: {command}\")\n",
    "        if command == \"exit\":\n",
    "            print(\"Custom exit action triggered.\")\n",
    "            listener.stop()\n",
    "\n",
    "\n",
    "    listener.set_command_listener(custom_command_listener)\n",
    "\n",
    "    # Start the voice command listener\n",
    "    listener.start()\n",
    "\n",
    "    # Wait for the thread to halt\n",
    "    listener.wait()\n",
    "\n",
    "    # Stop the listener after it halts (if necessary)\n",
    "    listener.stop()"
   ],
   "id": "86f2cbda27c03a5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio thread started.\n",
      "Waiting for audio thread to halt...\n",
      "Listening for trigger term...\n",
      "Heard: you\n",
      "Heard: which needs technology and so forth.\n",
      "Heard: is the kepler broad.\n",
      "Heard: is the radius of the earth.\n",
      "Heard: you might wonder how the ancients first...\n",
      "Heard: the earth you have to use a...\n",
      "Heard: it could be a flat disc.\n",
      "Heard: most of you find this pretty intuitive.\n",
      "Heard: and he shared with me a nice proof of\n",
      "Heard: in 3d there's enough...\n",
      "Heard: because he knew about lunar eclipses.\n",
      "Heard: there's a picture i can show you.\n",
      "Heard: this is visible proof of the other's truth.\n",
      "Heard: \n",
      "Heard: as well in this time period.\n",
      "Heard: i'm gonna go and try to see if i can get a little bit of a better view of the view from the top. i'm gonna go and try to see if i can get a little bit of a better view of the view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top. i'm gonna go and try to see if i can get a little bit of a better view from the top.\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: \n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: \n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n",
      "Heard: you\n",
      "Heard: you\n",
      "Heard: thanks for watching!\n",
      "Heard: thanks for watching!\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T10:52:12.359145Z",
     "start_time": "2025-02-09T10:51:40.685506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "class SpeechManager:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the SpeechManager with a non-blocking TTS engine.\n",
    "        \"\"\"\n",
    "        self.speech_queue = queue.Queue()\n",
    "        self.is_running = True\n",
    "        self.should_stop = False\n",
    "\n",
    "        # Start a thread to process the speech queue\n",
    "        self.speech_thread = threading.Thread(target=lambda: print(\"Speach tread\"))\n",
    "        self._process_queue()\n",
    "        self.speech_thread.daemon = True\n",
    "        self.speech_thread.start()\n",
    "\n",
    "    def queue_speech(self, text, prepend=False, interrupt_current=False):\n",
    "        \"\"\"\n",
    "        Queue text for speech synthesis.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be spoken.\n",
    "            prepend (bool): If True, add the text to the front of the queue.\n",
    "            interrupt_current (bool): If True, interrupt the current speech and play this text immediately.\n",
    "        \"\"\"\n",
    "\n",
    "        if interrupt_current:\n",
    "            self.engine.stop()\n",
    "            temp_queue = queue.Queue()\n",
    "            temp_queue.put(text)\n",
    "            self.speech_queue = temp_queue\n",
    "        elif prepend:\n",
    "            # Add the text to the front of the queue\n",
    "            temp_queue = queue.Queue()\n",
    "            temp_queue.put(text)\n",
    "            while not self.speech_queue.empty():\n",
    "                temp_queue.put(self.speech_queue.get())\n",
    "            self.speech_queue = temp_queue\n",
    "        else:\n",
    "            self.speech_queue.put(text)\n",
    "\n",
    "    def cancel_all(self):\n",
    "        \"\"\"\n",
    "        Interrupt the current speech.\n",
    "        \"\"\"\n",
    "        self.speech_queue = queue.Queue()\n",
    "        self.engine.stop()  # Stop the current speech\n",
    "\n",
    "    def _process_queue(self):\n",
    "        \"\"\"\n",
    "        Process the speech queue in a separate thread.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.engine = pyttsx3.init()\n",
    "            print(\"Saying...\")\n",
    "            self.engine.say(\"How are u?\")\n",
    "            self.engine.runAndWait()\n",
    "            return\n",
    "            while not self.should_stop:\n",
    "                if not self.speech_queue.empty():\n",
    "                    text = self.speech_queue.get()\n",
    "                    self._speak(text)\n",
    "                else:\n",
    "                    threading.Event().wait(0.1)  # Sleep briefly to avoid busy-waiting\n",
    "        except Exception as e:\n",
    "            print(\"Speach manager error:\", e)\n",
    "        finally:\n",
    "            self.is_running = False\n",
    "\n",
    "    def _speak(self, text):\n",
    "        \"\"\"\n",
    "        Speak the given text using the TTS engine in a non-blocking way.\n",
    "        \"\"\"\n",
    "\n",
    "        def _on_start(name):\n",
    "            print(f\"Started speaking: {text}\")\n",
    "\n",
    "        def _on_end(name, completed):\n",
    "            print(f\"Finished speaking: {text}\")\n",
    "\n",
    "        # Register event callbacks\n",
    "        self.engine.connect('started-utterance', _on_start)\n",
    "        self.engine.connect('finished-utterance', _on_end)\n",
    "\n",
    "        # Speak the text\n",
    "        self.engine.say(text)\n",
    "        self.engine.iterate()  # Process the speech without blocking\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stop the speech manager and clean up resources.\n",
    "        \"\"\"\n",
    "        self.should_stop = True\n",
    "        self.engine.stop()\n",
    "\n",
    "    # Additional methods for configuration\n",
    "    def set_rate(self, rate):\n",
    "        \"\"\"\n",
    "        Set the speech rate (words per minute).\n",
    "        \"\"\"\n",
    "        self.engine.setProperty('rate', rate)\n",
    "\n",
    "    def set_volume(self, volume):\n",
    "        \"\"\"\n",
    "        Set the speech volume (0.0 to 1.0).\n",
    "        \"\"\"\n",
    "        self.engine.setProperty('volume', volume)\n",
    "\n",
    "    def set_voice(self, voice_id):\n",
    "        \"\"\"\n",
    "        Set the voice by ID.\n",
    "        \"\"\"\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        if 0 <= voice_id < len(voices):\n",
    "            self.engine.setProperty('voice', voices[voice_id].id)\n",
    "\n",
    "    def get_available_voices(self):\n",
    "        \"\"\"\n",
    "        Get a list of available voices.\n",
    "        \"\"\"\n",
    "        return self.engine.getProperty('voices')\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    manager = SpeechManager()\n",
    "\n",
    "    # Queue some speech\n",
    "    manager.queue_speech(\"Hello, how are you?\")\n",
    "    manager.queue_speech(\"This is a test.\", prepend=True)\n",
    "    manager.queue_speech(\"I will interrupt now.\", interrupt_current=True)\n",
    "\n",
    "    # Configure TTS\n",
    "    # manager.set_rate(150)\n",
    "    # manager.set_volume(0.8)\n",
    "    # manager.set_voice(0)\n",
    "\n",
    "    # Keep the main thread alive to allow the speech thread to run\n",
    "    import time\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        manager.stop()\n",
    "        print(\"Speech manager stopped.\")"
   ],
   "id": "42ca66d3be938af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saying...\n",
      "Speach tread\n",
      "Speech manager stopped.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7f07a6d035bd6801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:03:49.525784Z",
     "start_time": "2025-02-10T10:03:45.244024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()  # object creation\n",
    "\n",
    "\"\"\" RATE\"\"\"\n",
    "rate = engine.getProperty('rate')  # getting details of current speaking rate\n",
    "print(rate)  #printing current voice rate\n",
    "engine.setProperty('rate', 125)  # setting up new voice rate\n",
    "\n",
    "\"\"\"VOLUME\"\"\"\n",
    "volume = engine.getProperty('volume')  #getting to know current volume level (min=0 and max=1)\n",
    "print(volume)  #printing current volume level\n",
    "engine.setProperty('volume', 1.0)  # setting up volume level  between 0 and 1\n",
    "\n",
    "\"\"\"VOICE\"\"\"\n",
    "voices = engine.getProperty('voices')  #getting details of current voice\n",
    "#engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "engine.setProperty('voice', voices[100].id)  #changing index, changes voices. 1 for female\n",
    "\n",
    "engine.say(\"Hello World!\")\n",
    "engine.say('My current speaking rate is ' + str(rate))\n",
    "engine.runAndWait()\n",
    "engine.stop()\n"
   ],
   "id": "d89d309a1aec33c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "1.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T10:59:40.371906Z",
     "start_time": "2025-02-09T10:59:39.063972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "tts = gTTS(\"Hello, this is a test, is not it?.\")\n",
    "tts.save(\"output.mp3\")\n"
   ],
   "id": "51f88c8968e91229",
   "outputs": [
    {
     "ename": "gTTSError",
     "evalue": "Failed to connect. Probable cause: Unknown",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connection.py:198\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 198\u001B[0m     sock \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m        \u001B[49m\u001B[43msource_address\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[43msocket_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msocket_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/util/connection.py:60\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LocationParseError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, label empty or too long\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 60\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43msocket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfamily\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msocket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSOCK_STREAM\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     61\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[0;32m/usr/lib/python3.12/socket.py:976\u001B[0m, in \u001B[0;36mgetaddrinfo\u001B[0;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[1;32m    975\u001B[0m addrlist \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43m_socket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfamily\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    977\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "\u001B[0;31mgaierror\u001B[0m: [Errno -2] Name or service not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mNameResolutionError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:488\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    487\u001B[0m         new_e \u001B[38;5;241m=\u001B[39m _wrap_proxy_error(new_e, conn\u001B[38;5;241m.\u001B[39mproxy\u001B[38;5;241m.\u001B[39mscheme)\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m new_e\n\u001B[1;32m    490\u001B[0m \u001B[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001B[39;00m\n\u001B[1;32m    491\u001B[0m \u001B[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:464\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 464\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1093\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_closed:\n\u001B[0;32m-> 1093\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connection.py:704\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    703\u001B[0m sock: socket\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m|\u001B[39m ssl\u001B[38;5;241m.\u001B[39mSSLSocket\n\u001B[0;32m--> 704\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m sock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m server_hostname: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NameResolutionError(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m, e) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mNameResolutionError\u001B[0m: <urllib3.connection.HTTPSConnection object at 0x7f8fd2be8650>: Failed to resolve 'translate.google.com' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    839\u001B[0m     new_e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, new_e)\n\u001B[0;32m--> 841\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    844\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    518\u001B[0m     reason \u001B[38;5;241m=\u001B[39m error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause)\n\u001B[0;32m--> 519\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, reason) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mreason\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    521\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[0;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='translate.google.com', port=443): Max retries exceeded with url: /_/TranslateWebserverUi/data/batchexecute (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f8fd2be8650>: Failed to resolve 'translate.google.com' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py:268\u001B[0m, in \u001B[0;36mgTTS.stream\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m s:\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;66;03m# Send request\u001B[39;00m\n\u001B[0;32m--> 268\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetproxies\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders-\u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, idx, r\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/requests/adapters.py:700\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    698\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m--> 700\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mConnectionError\u001B[0m: HTTPSConnectionPool(host='translate.google.com', port=443): Max retries exceeded with url: /_/TranslateWebserverUi/data/batchexecute (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f8fd2be8650>: Failed to resolve 'translate.google.com' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mgTTSError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgtts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gTTS\n\u001B[1;32m      2\u001B[0m tts \u001B[38;5;241m=\u001B[39m gTTS(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHello, this is a test, is not it?.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput.mp3\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py:335\u001B[0m, in \u001B[0;36mgTTS.save\u001B[0;34m(self, savefile)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Do the TTS API request and write result to file.\u001B[39;00m\n\u001B[1;32m    326\u001B[0m \n\u001B[1;32m    327\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mstr\u001B[39m(savefile), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_to_fp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m     f\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    337\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaved to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, savefile)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py:316\u001B[0m, in \u001B[0;36mgTTS.write_to_fp\u001B[0;34m(self, fp)\u001B[0m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Do the TTS API request(s) and write bytes to a file-like object.\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \n\u001B[1;32m    306\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    312\u001B[0m \n\u001B[1;32m    313\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdebug\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpart-\u001B[39;49m\u001B[38;5;132;43;01m%i\u001B[39;49;00m\u001B[38;5;124;43m written to \u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py:287\u001B[0m, in \u001B[0;36mgTTS.stream\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Request failed\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;28mstr\u001B[39m(e))\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m gTTSError(tts\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# Write\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_lines(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m):\n",
      "\u001B[0;31mgTTSError\u001B[0m: Failed to connect. Probable cause: Unknown"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from TTS.api import TTS\n",
    "import threading\n",
    "\n",
    "\n",
    "class OfflineTTS:\n",
    "    def __init__(self, model_name=\"tts_models/en/ljspeech/tacotron2-DDC\"):\n",
    "        self.tts = TTS(model_name)\n",
    "        self.speech_queue = queue.Queue()\n",
    "        self.speaking_thread = threading.Thread(target=self._process_queue, daemon=True)\n",
    "        self.speaking_thread.start()\n",
    "\n",
    "    def _process_queue(self):\n",
    "        while True:\n",
    "            text = self.speech_queue.get()\n",
    "            if text is None:\n",
    "                break\n",
    "            audio = self.tts.tts(text)\n",
    "            sd.play(np.array(audio), samplerate=22050)\n",
    "            sd.wait()\n",
    "            self.speech_queue.task_done()\n",
    "\n",
    "    def queue_speech(self, text):\n",
    "        \"\"\"Adds text to the speech queue.\"\"\"\n",
    "        self.speech_queue.put(text)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stops the speech thread.\"\"\"\n",
    "        self.speech_queue.put(None)\n",
    "        self.speaking_thread.join()\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "tts = OfflineTTS()\n",
    "tts.queue_speech(\"This is an advanced offline text to speech system.\")\n"
   ],
   "id": "8587da37d8c943cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:59:53.870003Z",
     "start_time": "2025-02-09T19:59:45.617379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the Whisper model (choose 'tiny', 'base', 'small', 'medium', 'large')\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "# Audio recording settings\n",
    "SAMPLE_RATE = 16000  # Whisper expects 16kHz audio\n",
    "DURATION = 5  # Recording duration in seconds per chunk\n",
    "my_data = None\n",
    "\n",
    "\n",
    "def callback(indata, frames, t, status):\n",
    "    \"\"\"Callback function to process live audio\"\"\"\n",
    "    if status:\n",
    "        print(f\"Error: {status}\", flush=True)\n",
    "\n",
    "    print(indata.mean())\n",
    "    # print({'frames': frames, 't': t.inputBufferAdcTime, 'status': status}, t.outputBufferDacTime, t.currentTime)\n",
    "    # global my_data\n",
    "    # my_data = {'indata': indata.copy(), 'frames': frames, 't': t.inputBufferAdcTime, 'status': status}\n",
    "\n",
    "\n",
    "# Start recording stream\n",
    "with sd.InputStream(callback=callback, samplerate=SAMPLE_RATE, channels=1, dtype=\"float32\", blocksize= 1024) as s:\n",
    "    print(\"Listening...\")\n",
    "    while my_data is None:\n",
    "        pass  # Keep the program running\n",
    "    s.close()\n",
    "    print(my_data)\n"
   ],
   "id": "f689f27c19d66753",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "3.7608468e-05\n",
      "-2.3893084e-05\n",
      "0.00015052049\n",
      "0.001430799\n",
      "-0.0018630526\n",
      "0.0017473453\n",
      "-0.00022819405\n",
      "-0.0007436129\n",
      "-0.002691816\n",
      "0.0021951543\n",
      "0.0012475958\n",
      "0.0014084931\n",
      "-0.0024839835\n",
      "-0.002391302\n",
      "-0.00017613638\n",
      "0.0020508554\n",
      "0.0014517119\n",
      "0.0006688951\n",
      "-0.0031393073\n",
      "-0.00027830782\n",
      "0.00068402616\n",
      "0.0017732056\n",
      "0.00060093135\n",
      "-0.00402719\n",
      "0.0038303076\n",
      "-0.0021085497\n",
      "-0.0026303623\n",
      "0.0037994944\n",
      "-0.0008425764\n",
      "0.0007975693\n",
      "-0.0017228504\n",
      "0.0027028946\n",
      "-0.0001131919\n",
      "-0.0030194048\n",
      "0.0012038369\n",
      "0.001891919\n",
      "0.00029250327\n",
      "-0.0015731137\n",
      "-0.0016451626\n",
      "0.0049984637\n",
      "-0.0019552168\n",
      "-0.0037578563\n",
      "0.001023693\n",
      "0.0035909545\n",
      "-0.001520654\n",
      "-0.0008967833\n",
      "-0.0004839748\n",
      "0.00048493827\n",
      "0.00017809274\n",
      "0.001355524\n",
      "-0.0004700967\n",
      "3.6451733e-05\n",
      "0.00013708766\n",
      "-0.0014031488\n",
      "0.0012123832\n",
      "0.00045090192\n",
      "0.001947539\n",
      "-0.0012444486\n",
      "-0.0035801772\n",
      "0.0018975968\n",
      "0.000333959\n",
      "0.00024909782\n",
      "-0.0003949767\n",
      "-0.0029249429\n",
      "0.0035456454\n",
      "0.00019048993\n",
      "-0.0026862193\n",
      "0.0017250844\n",
      "0.0017865426\n",
      "-0.0013352802\n",
      "-0.0025233817\n",
      "0.0023488617\n",
      "0.0019271557\n",
      "-0.00050330465\n",
      "-0.0029495498\n",
      "-0.0013265784\n",
      "0.0042735296\n",
      "-0.0043001673\n",
      "0.0009267025\n",
      "0.0040070442\n",
      "-0.002936238\n",
      "0.0024516366\n",
      "-0.0011575641\n",
      "-0.0010399347\n",
      "0.0036055176\n",
      "-0.0009682649\n",
      "-0.0019122954\n",
      "-0.002703275\n",
      "0.0024610152\n",
      "0.001083544\n",
      "-0.0015917355\n",
      "0.0012021824\n",
      "-0.00081167114\n",
      "-0.0007631236\n",
      "-0.0012503967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 30\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sd\u001B[38;5;241m.\u001B[39mInputStream(callback\u001B[38;5;241m=\u001B[39mcallback, samplerate\u001B[38;5;241m=\u001B[39mSAMPLE_RATE, channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m, blocksize\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m s:\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mListening...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m my_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Keep the program running\u001B[39;00m\n\u001B[1;32m     32\u001B[0m     s\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T18:05:29.872152Z",
     "start_time": "2025-02-09T18:03:53.103525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import vosk\n",
    "\n",
    "# Load Vosk model (change path if needed)\n",
    "MODEL_PATH = \"../vosk-model\"\n",
    "model = vosk.Model(MODEL_PATH)\n",
    "\n",
    "# Create a queue to hold recorded audio\n",
    "q = queue.Queue()\n",
    "\n",
    "# Audio recording settings\n",
    "SAMPLE_RATE = 16000  # Vosk expects 16kHz audio\n",
    "CHANNELS = 1\n",
    "\n",
    "# Speech recognizer\n",
    "recognizer = vosk.KaldiRecognizer(model, SAMPLE_RATE)\n",
    "\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    \"\"\"Callback function to process live audio\"\"\"\n",
    "    if status:\n",
    "        print(f\"Error: {status}\", flush=True)\n",
    "    q.put(bytes(indata))  # Put audio data into the queue\n",
    "\n",
    "\n",
    "# Start recording stream\n",
    "with sd.InputStream(callback=callback, samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=\"int16\"):\n",
    "    print(\"Listening...\")\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            print(f\"Transcribed: {result['text']}\")\n"
   ],
   "id": "c2580cdb329f9a25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ../vosk-model/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from ../vosk-model/graph/HCLr.fst ../vosk-model/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo ../vosk-model/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Transcribed: the\n",
      "Transcribed: he declined here is not pointed towards the sun it's it's it's i'm angel with all of those raise he had ah what could have a norman which is kind of like an ancient protracted was under the portals under\n",
      "Transcribed: key measure that the sun was occupied seven degrees of of it\n",
      "Transcribed: critically because he could also noted at this exact moment down and so many many many miles away the sun was directly overhead he deduced that this means the arc length along earth between alexandria insane is about seven degrees this in turn means the ratio between seven degrees and the for three hundred sixty degrees of a circle\n",
      "Transcribed: must be the same as the ratio of the distance between those two towns and the full circumference of the earth\n",
      "Transcribed: no keep in mind in the records that we have it's not like he's reporting this distance in miles or kilometers the units they were using back then word stevia were a single unit is something like the length of a stadium for the distance was about case or as a stadium which is about outermost\n",
      "Transcribed: how accurate is are converted between stadia that's a good question we are not completely certain so with the committee accepted conversions i think the accuracy where tossed nice estimates about it wasn't you can find sources online that clean his estimate was more accurate than this but just keep in mind if you selectively choose which of the many possible conversions between stadia and my\n",
      "Transcribed: else to use you can kind of p hack your way into a better number here still ten\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 30\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mListening...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 30\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recognizer\u001B[38;5;241m.\u001B[39mAcceptWaveform(data):\n\u001B[1;32m     32\u001B[0m         result \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(recognizer\u001B[38;5;241m.\u001B[39mResult())\n",
      "File \u001B[0;32m/usr/lib/python3.12/queue.py:171\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qsize():\n\u001B[0;32m--> 171\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a non-negative number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/lib/python3.12/threading.py:355\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 355\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    356\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbd45a8e4ac0ca9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:31:19.614840Z",
     "start_time": "2025-02-10T06:30:59.148526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy  # Make sure NumPy is loaded before it is used in the callback\n",
    "assert numpy  # avoid \"imported but unused\" message (W0611)\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# Set up the model and recognizer\n",
    "# model_path = \"path_to_your_vosk_model\"  # Replace with the path to your Vosk model\n",
    "# if not os.path.exists(model_path):\n",
    "#     print(f\"Please download a model from https://alphacephei.com/vosk/models and unpack as {model_path}\")\n",
    "#     sys.exit(1)\n",
    "# \n",
    "# model = Model(model_path)\n",
    "model = Model(lang='en-us')\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# Audio settings\n",
    "samplerate = 16000\n",
    "blocksize = 8000\n",
    "device = None  # Use the default input device\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    \"\"\"This is called (from a separate thread) for each audio block.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "try:\n",
    "    with sd.RawInputStream(samplerate=samplerate, blocksize=blocksize, device=device,\n",
    "                           dtype='int16', channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('Press Ctrl+C to stop the recording')\n",
    "        print('#' * 80)\n",
    "\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                result = recognizer.Result()\n",
    "                print(result)\n",
    "            else:\n",
    "                partial_result = recognizer.PartialResult()\n",
    "                print(partial_result)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nDone')\n",
    "except Exception as e:\n",
    "    print(type(e).__name__ + ': ' + str(e))"
   ],
   "id": "9a698f6d16228d7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /home/yoni_ash/.cache/vosk/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /home/yoni_ash/.cache/vosk/vosk-model-small-en-us-0.15/graph/HCLr.fst /home/yoni_ash/.cache/vosk/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /home/yoni_ash/.cache/vosk/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Press Ctrl+C to stop the recording\n",
      "################################################################################\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"did\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"did you have is that\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"did you have is that the\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"did you have is that visiting\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"this\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"this edition\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"this edition\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"not for this\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"not for this\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"not for this\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"leaving\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"living in\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"living in\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"living and\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"that\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the perfect and\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the perfect and\"\n",
      "}\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:32:18.929884Z",
     "start_time": "2025-02-10T09:31:58.084298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "import tempfile\n",
    "import pygame\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "class LiveTextToSpeech:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the LiveTextToSpeech class.\"\"\"\n",
    "        self.speech_queue = queue.Queue()\n",
    "        self.current_speech = None\n",
    "        self.running = False\n",
    "        self.lock = threading.Lock()\n",
    "        self.thread = None\n",
    "\n",
    "    def queue_speech(self, text, prepend=False, interrupt=False):\n",
    "        \"\"\"\n",
    "        Add speech to the queue.\n",
    "        :param text: The text to convert to speech.\n",
    "        :param prepend: If True, add to the front of the queue.\n",
    "        :param interrupt: If True, cancel the currently playing speech and prepend this one.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            if interrupt and self.current_speech:\n",
    "                self._stop_current_speech()\n",
    "                self.speech_queue.queue.clear()  # Clear the queue if interrupting\n",
    "                self.speech_queue.put(text)  # Prepend the new speech\n",
    "            elif prepend:\n",
    "                # Move all items to a temporary list, add the new item, then re-add the rest\n",
    "                temp_list = []\n",
    "                while not self.speech_queue.empty():\n",
    "                    temp_list.append(self.speech_queue.get())\n",
    "                self.speech_queue.put(text)\n",
    "                for item in temp_list:\n",
    "                    self.speech_queue.put(item)\n",
    "            else:\n",
    "                self.speech_queue.put(text)\n",
    "\n",
    "            if not self.running:\n",
    "                self._start_processing()\n",
    "\n",
    "    def cancel_all(self):\n",
    "        \"\"\"Cancel all queued speech.\"\"\"\n",
    "        with self.lock:\n",
    "            self.speech_queue.queue.clear()\n",
    "            if self.current_speech:\n",
    "                self._stop_current_speech()\n",
    "\n",
    "    def _start_processing(self):\n",
    "        \"\"\"Start processing the speech queue in a separate thread.\"\"\"\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._process_queue, daemon=True)\n",
    "        self.thread.start()\n",
    "\n",
    "    def _process_queue(self):\n",
    "        \"\"\"Process the speech queue.\"\"\"\n",
    "        while self.running:\n",
    "            try:\n",
    "                text = self.speech_queue.get(timeout=1)\n",
    "                self._play_speech(text)\n",
    "                self.speech_queue.task_done()\n",
    "            except queue.Empty:\n",
    "                if self.speech_queue.empty():\n",
    "                    self.running = False\n",
    "                    break\n",
    "\n",
    "    def _play_speech(self, text):\n",
    "        \"\"\"Convert text to speech and play it.\"\"\"\n",
    "        with self.lock:\n",
    "            self.current_speech = text\n",
    "            try:\n",
    "                # Create a temporary file for the speech\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
    "                    tts = gTTS(text=text, lang=\"en\")\n",
    "                    tts.save(temp_file.name)\n",
    "                    temp_file_path = temp_file.name\n",
    "\n",
    "                # Play the speech using pygame\n",
    "                pygame.mixer.init()\n",
    "                pygame.mixer.music.load(temp_file_path)\n",
    "                pygame.mixer.music.play()\n",
    "\n",
    "                # Wait for the speech to finish\n",
    "                while pygame.mixer.music.get_busy():\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                # Clean up\n",
    "                pygame.mixer.quit()\n",
    "                os.remove(temp_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error playing speech: {e}\")\n",
    "            finally:\n",
    "                self.current_speech = None\n",
    "\n",
    "    def _stop_current_speech(self):\n",
    "        \"\"\"Stop the currently playing speech.\"\"\"\n",
    "        if pygame.mixer.get_init():\n",
    "            pygame.mixer.music.stop()\n",
    "            pygame.mixer.quit()\n",
    "        self.current_speech = None\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up resources when the object is deleted.\"\"\"\n",
    "        self.cancel_all()\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "            \n",
    "def main():\n",
    "    tts = LiveTextToSpeech()\n",
    "\n",
    "    # Queue some speech\n",
    "    tts.queue_speech(\"Hello, how are you?\")\n",
    "    tts.queue_speech(\"This is a test.\")\n",
    "    tts.queue_speech(\"Goodbye!\")\n",
    "\n",
    "    # Wait for a few seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Interrupt with a new speech\n",
    "    tts.queue_speech(\"Wait, I have something important to say!\", interrupt=True)\n",
    "\n",
    "    # Wait for the speech to finish\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Cancel all speech\n",
    "    tts.cancel_all()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "9ab2b12e3f9407eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:54:33.222240Z",
     "start_time": "2025-02-10T09:54:27.305145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "text = \"\"\"In 1869, the stock ticker was invented. It was an electro-mechanical machine consisting of a typewriter, a long pair of wires and a ticker tape printer, and its purpose was to distribute stock prices over long distances in realtime. This concept gradually evolved into the faster, ASCII-based teletype. Teletypes were once connected across the world in a large network, called Telex, which was used for transferring commercial telegrams, but the teletypes weren't connected to any computers yet.\n",
    "\n",
    "Meanwhile, however, the computers — still quite large and primitive, but able to multitask — were becoming powerful enough to be able to interact with users in realtime. When the command line eventually replaced the old batch processing model, teletypes were used as input and output devices, because they were readily available on the market.\n",
    "\n",
    "There was a plethora of teletype models around, all slightly different, so some kind of software compatibility layer was called for. In the UNIX world, the approach was to let the operating system kernel handle all the low-level details, such as word length, baud rate, flow control, parity, control codes for rudimentary line editing and so on. Fancy cursor movements, colour output and other advanced features made possible in the late 1970s by solid state video terminals such as the VT-100, were left to the applications.\"\"\"\n",
    "\n",
    "import io\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function to split text into smaller chunks (sentences/phrases)\n",
    "def split_text(text):\n",
    "    return re.split(r'([,.!?;])', text)\n",
    "\n",
    "# Function to process and play text in chunks\n",
    "def speak_chunk(sentence):\n",
    "    \"\"\"Function to process a single sentence and play it\"\"\"\n",
    "    sentence = sentence.strip()  # Clean leading/trailing spaces\n",
    "\n",
    "    if sentence:  # Ensure the sentence is not empty\n",
    "        # Convert text to speech\n",
    "        tts = gTTS(sentence)\n",
    "        audio_buffer = io.BytesIO()\n",
    "        tts.write_to_fp(audio_buffer)\n",
    "        audio_buffer.seek(0)\n",
    "\n",
    "        # Load and convert audio\n",
    "        audio = AudioSegment.from_file(audio_buffer, format=\"mp3\")\n",
    "        samples = np.array(audio.get_array_of_samples(), dtype=np.float32) / 32768.0\n",
    "\n",
    "        # Handle stereo\n",
    "        if audio.channels == 2:\n",
    "            samples = samples.reshape((-1, 2))\n",
    "\n",
    "        # Play chunk\n",
    "        sd.play(samples, samplerate=audio.frame_rate)\n",
    "        sd.wait()\n",
    "\n",
    "# Function to process and play text in chunks\n",
    "def speak_text(text):\n",
    "    chunks = split_text(text)\n",
    "    sentence = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        sentence += chunk\n",
    "        if chunk.strip() in {\".\", \",\", \"!\", \"?\", \";\"} or len(sentence) > 20:\n",
    "            # Buffer next chunk while playing the current one\n",
    "            threading.Thread(target=speak_chunk, args=(sentence,)).start()\n",
    "            sentence = \"\"  # Reset for next chunk\n",
    "\n",
    "            time.sleep(0.1)  # Small delay to buffer in parallel (can be adjusted)\n",
    "\n",
    "# Example usage\n",
    "# text = \"Hello! This is a test. Breaking text improves real-time playback.\"\n",
    "speak_text(text)\n",
    "\n"
   ],
   "id": "cc8a7c65cdd8066a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
      "/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
      "/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
      "/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
      "Exception in thread Thread-7 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-9 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-11 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-13 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-15 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-17 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-19 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-22 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-24 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-28 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-30 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-32 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-34 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-36 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-38 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-40 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-42 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-45 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-51 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-53 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-55 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n",
      "Exception in thread Thread-57 (speak_chunk):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_129000/4252342460.py\", line 29, in speak_chunk\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 316, in write_to_fp\n",
      "    for idx, decoded in enumerate(self.stream()):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 263, in stream\n",
      "    prepared_requests = self._prepare_requests()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yoni_ash/.cache/pypoetry/virtualenvs/smart-cane-UziNl_FU-py3.12/lib/python3.12/site-packages/gtts/tts.py\", line 210, in _prepare_requests\n",
      "    assert text_parts, \"No text to send to TTS API\"\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: No text to send to TTS API\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from RealtimeTTS import TextToAudioStream, SystemEngine, AzureEngine, ElevenlabsEngine\n",
    "\n",
    "engine = SystemEngine() # replace with your TTS engine\n",
    "stream = TextToAudioStream(engine)\n",
    "stream.feed(\"Hello world! How are you today?\")\n",
    "stream.play_async()"
   ],
   "id": "ca8cc5c313a7e908"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
